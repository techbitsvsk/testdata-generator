# TPC-DS Query Complexity and Spark Kubernetes Resource Impact Summary (2.4TB Dataset)

**Current Date & Time:** Saturday, June 21, 2025 at 10:09:55 PM BST
**Location:** Glasgow, Scotland, United Kingdom

**Cluster Configuration Context:** 16 Executors, 12GB Memory (per container, includes overhead), 2 vCPUs (per executor). Data size: 2.4TB TPC-DS.

**Impact Scale:**
* **Low**: Minimal impact, easily handled.
* **Moderate**: Manageable, typical operations, might see some resource usage.
* **High**: Significant resource consumption, potential for bottlenecks if not tuned.
* **Very High**: Major resource consumption, likely to be a bottleneck, strong potential for spills/slowdowns.
* **Extremely High**: Critical resource consumption, almost guaranteed spills, major bottlenecks, requires significant tuning or architecture changes.

---

| Query ID   | Query Name                                          | Query Type                                                 | Key Complexities                                                                                                                                                                                                                                                                                                                                                                                                                                                   | Memory Impact (Executor)                                                                                                                                                                                             | Storage (Disk I/O) Impact                                                                                                                                                                                     | Data Shuffle Impact                                                                                                                                                                                                  | Network Impact                                                                                                                                                           |
| :--------- | :-------------------------------------------------- | :--------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :--------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Q0** | Multi-channel Sales Analysis (with Rank Filter)     | Multi-source Aggregation, Window Function (`RANK`), Multi-table Join, **Highly Selective Filter (`category_rank`)**, Granular Aggregation. | - `UNION ALL` across 3 fact tables (initial high data read).<br/>- `RANK()` window function: Requires shuffle & in-partition sort on `(i_category, d_year)` (potentially large partitions).<br/>- **CRITICAL: `WHERE r.category_rank <= 50` filter**: Drastically prunes rows *after* the window function, making subsequent steps much cheaper.<br/>- Multiple joins (5 total).<br/>- Granular `GROUP BY` (16 columns), but on a *filtered* dataset. | **High (at `ranked_items` stage), then Moderate**: `RANK()` demands significant memory for sorting within partitions. Post-filter, memory needs for joins/aggregations drop significantly due to reduced data volume. | **High (at `ranked_items` stage), then Moderate**: `RANK()` may cause shuffle spills. Once data is filtered by `category_rank`, I/O for subsequent shuffles and writes is much lower.                                   | **High (at `ranked_items` stage), then Moderate**: `RANK()`'s `PARTITION BY` causes large shuffle. After `category_rank` filter, shuffles for final joins/group by are greatly reduced. | **High (at `ranked_items` stage), then Moderate**: Driven by `RANK()`'s large shuffle. Subsequent network traffic is significantly lower due to pruning. |
| **Q_CUBE** | Combinatorial Analysis of Profitability (GROUP BY CUBE) | Multi-table Join, **Extensive Aggregation (`GROUP BY CUBE`)**, Complex Aggregations, `HAVING`, `ORDER BY`. | - Joins fact with dims (`d.d_year = 2001` helps filter initial data).<br/>- **`GROUP BY CUBE (4 columns)`**: Generates $2^4 = 16$ grouping sets (all combinations), leading to a massive number of aggregated output rows.<br/>- **`COUNT(DISTINCT sb.ss_ticket_number)`**: Applied across all 16 grouping sets, `ss_ticket_number` is very high-cardinality, making this extremely expensive.<br/>- `HAVING` clause filters *after* full aggregation.<br/>- Global `ORDER BY` of massive result set. | **Extremely High**: `CUBE` with 16 grouping sets and `COUNT(DISTINCT)` demands enormous memory for hash tables/aggregates. Almost guaranteed extensive memory spills to local disk. High GC pressure.                   | **Extremely High**: **Massive shuffle spills** are almost guaranteed due to memory limits, requiring high disk write/read activity on executor local storage. Numerous temporary files for intermediate sorts/hashes.     | **Extremely High**: `CUBE` aggregation necessitates massive shuffles (for all 16 grouping sets). `COUNT(DISTINCT)` adds further shuffles. Final global `ORDER BY` requires another very large shuffle. | **Extremely High**: Dominated by the immense data shuffle volume. Extreme pressure on network bandwidth. Network latency becomes a major bottleneck.           |
```